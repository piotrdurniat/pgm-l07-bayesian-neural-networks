{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przed oddaniem zadania upewnij się, że wszystko działa poprawnie.\n",
    "**Uruchom ponownie kernel** (z paska menu: Kernel$\\rightarrow$Restart) a następnie\n",
    "**wykonaj wszystkie komórki** (z paska menu: Cell$\\rightarrow$Run All).\n",
    "\n",
    "Upewnij się, że wypełniłeś wszystkie pola `TU WPISZ KOD` lub `TU WPISZ ODPOWIEDŹ`, oraz\n",
    "że podałeś swoje imię i nazwisko poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesowskie Sieci Neuronowe (ang. *Bayesian Neural Networks*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BSN (Bayesowskie Sieci Neuronowe) są rozszerzeniem tradycyjnych sieci neuronowych o elementy wnioskowania i uczenia Bayesowskiego. Wśród zalet tych sieci możemy wskazać:\n",
    "- możliwość pomiaru niepewności modelu (*uncertainty*) dla predykcji (przy różnych poziomach pewności - ang. *confidence levels*)\n",
    "- istnieje możliwość zakodowanie wiedzy apriori na temat rozkładu wag sieci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podejście Bayesowskie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W przypadku zwykłych sieci neuronowych parametry (wagi) sieci estymujemy metodą Maximum Likelihood, która maksymalizuje prawdopodobieństwo obserwowania danych $\\mathcal{D}$ pod warunkiem parametrów $\\mathbf{w}$:\n",
    "\n",
    "$$\n",
    "\\text{arg max}_\\theta p(\\mathcal{D}|\\mathbf{w})\n",
    "$$\n",
    "\n",
    "Skutkiem tego jest punktowa estymata parametrów, która nie pozwala modelować niepewności. Możemy jednak wykorzystać twierdzenie Bayesa i przekształcić problem do **uczenia rozkładu parametrów modelu**: \n",
    "\n",
    "$$\n",
    "p(\\mathbf{w} | \\mathcal{D}) = \\frac{p(\\mathcal{D}|\\mathbf{w})p(\\mathbf{w})}{p(\\mathcal{D})}\n",
    "$$\n",
    "\n",
    "W ten sposób opisujemy rozkład posteriora, gdzie $p(\\mathbf{w})$ to wiedza apriori na temat parametrów (wag) modelu. Używając wnioskowania Bayesowskiego, możemy uzyskać predykcje modelu obliczając całkę po całej przestrzeni parametrów $\\mathbf{w}$:\n",
    "\n",
    "\n",
    "$$\n",
    "p(y | x, \\mathcal{D}) = \\int p(y | x,\\mathbf{w}) p(\\mathbf{w} | \\mathcal{D})\\, d\\mathbf{w}\n",
    "$$\n",
    "\n",
    "Oczywiście taka całka jest praktycznie nie możliwa do policzenia - z jednej strony mamy nieskończenie wiele możliwych wartości parametrów, a ponadto nie znamy rozkładu danych.\n",
    "\n",
    "W literaturze zaproponowano kilka możliwych aproksymacji tego problemu:\n",
    "- jedną z nich jest [Stochastic Variational Inference](http://jmlr.org/papers/v14/hoffman13a.html) (2014) **i na niej skupimy się w tym zeszycie**\n",
    "- Monte Carlo Markov Chain (MCMC)\n",
    "\n",
    "\n",
    "Alternatywnie zamiast aproksymować rozkład predykcyjny możemy zaproksymować całą Bayesowską sieć neuronową -- np. za pomocą mechanizmu Dropout, w postaci metody Monte Carlo Dropout: [Yarin Gal and Zoubin Ghahramani in \"Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning\"](https://arxiv.org/abs/1506.02142)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na początku chcielibyśmy policzyć rozkład posterior parametrów $p(\\mathbf{w}|\\mathcal{D})$. Nie znamy tego rozkładu ani nie jesteśmy w stanie policzyć rozkładu danych $p(\\mathcal{D})$. Możemy jednak wykorzystać mechanizm Variational Inference. Określamy rozkład wariacyjny (ang. *variational distribution*), który pochodzi z rodziny znanych nam rozkładów (np. rozkład normalny) i powinien aproksymować skomplikowany nieznany nam rozkład. W poniższych wyprowadzeniach będziemy rozważać gausowski rozkład wariacyjny:\n",
    "\n",
    "$$\n",
    "q_\\theta(\\mathbf{w}) \\approx p(\\mathbf{w} | \\mathcal{D})\n",
    "$$\n",
    "\n",
    "$\\theta$ to parametry rozkładu wariacyjnego. W celu pomiaru jak dobrze rozkład wariacyjny aproksymuje ten pożądany (rzeczywisty) rozkład musimy określić pewną miarę odległości. Wykorzystamy dywergencję Kullbacka-Leiblera. Podczas optymalizacji problemu, będziemy poszukiwać optymalnych (najlepszych) parametrów rozkładu wariacyjnego, które minimalizują dywergencję KL:\n",
    "\n",
    "$$\n",
    "\\theta_{opt} = \\text{arg min}_\\theta \\text{KL}\\left[q_\\theta(\\mathbf{w}) || p(\\mathbf{w}|\\mathcal{D}) \\right]\n",
    "$$\n",
    "\n",
    "Dywergencja Kullbacka-Leiblera jest określona w następujący sposób:\n",
    "\n",
    "$$\n",
    "\\text{KL}\\left[q_\\theta(\\mathbf{w})||p(\\mathbf{w} | \\mathcal{D}) \\right] = \\int q_\\theta(\\mathbf{w}) \\log\\frac{q_\\theta(\\mathbf{w})}{p(\\mathbf{w}|\\mathcal{D})}\\, d\\mathbf{w}\n",
    "$$\n",
    "\n",
    "Aby policzyć tę całkę musimy znać rozkład posteriora $p(\\mathbf{w}|\\mathcal{D})$, dlatego stosujemy następujące przekształcenie:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\theta_{opt} &= \\text{arg min}_\\theta \\text{KL}\\left[q_\\theta(\\mathbf{w})||p(\\mathbf{w} | \\mathcal{D}) \\right] \\\\\n",
    "&= \\text{arg min}_\\theta \\int q_\\theta(\\mathbf{w}) \\log\\frac{q_\\theta(\\mathbf{w})}{p(\\mathbf{w})p(\\mathcal{D}|\\mathbf{w})}\\, d\\mathbf{w}\\\\\n",
    "&= \\text{arg min}_\\theta \\text{KL}\\left[q_\\theta(\\mathbf{w})||p(\\mathbf{w}) \\right] - {\\mathbb{E}}_{q_\\theta(\\mathbf{w})}\\left[log p(\\mathcal{D}|\\mathbf{w})\\right]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Tę wartość nazywamy [Evidence Lower Bound (ELBO)](https://en.wikipedia.org/wiki/Evidence_lower_bound)\n",
    "\n",
    "Aby uzyskać nieobciążone estymatory gradientów ELBO możemy zastosować estymację Monte Carlo losując wagi modelu $N$-krotnie i sumując wyniki kilku takich losowań. Podsumowując, optymalne wagi znajdujemy w następujący sposób:\n",
    "\n",
    "$$\\tag{1}\n",
    "\\theta_{opt} = \\text{arg min}_\\theta \\frac{1}{N}\\sum^N_{i=1} \\log q_\\theta(\\mathbf{w}^{(i)}) - \\log p(\\mathbf{w}^{(i)}) - \\log p(\\mathcal{D}|\\mathbf{w}^{(i)})\n",
    "$$\n",
    "\n",
    "gdzie $\\mathbf{w}^{(i)}$ jest próbkowane z rozkładu $q_\\theta(\\mathbf{w})$. Zauważ, że ostatni człon $\\log p(\\mathcal{D}|\\mathbf{w}^{(i)})$ to funkcja likelihood zwykłej sieci neuronowej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sztuczka z reparametryzacją (ang. *reparametrization trick*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolejnym problemem jest związanym z powyższą metodą jest brak możliwości obliczania pochodnych (brak różniczkowalności) w procesie optymalizacji parametrów sieci. Rozwiązaniem jest wykorzystanie sztuczki z reparametryzację (więcej szczegółów znajdziesz w [Variational Dropout and the Local Reparameterization Trick](https://arxiv.org/abs/1506.02557)). Zakładając, że chcemy wykorzystywać rozkład normalny, każdy wyuczalny parametr (waga) sieci $\\theta$ będzie określony przez dwa inne parametry - średnią  $\\mu$ oraz wariancję  $\\sigma^2$ rozkładu normalnego:\n",
    "\n",
    "$$\n",
    "\\theta = (\\mu, \\sigma^2)\n",
    "$$\n",
    "\n",
    "Używając sztuczki z reparametryzacją otrzymujemy:\n",
    "\n",
    "$$\n",
    "f(\\epsilon) = \\theta = \\mu + \\sigma \\cdot \\epsilon\n",
    "$$\n",
    "\n",
    "gdzie $\\epsilon$ jest losowany z rozkładu normalnego standardowego:\n",
    "\n",
    "$$\n",
    "\\epsilon \\sim \\mathcal{N}(0, 1)\n",
    "$$\n",
    "\n",
    "Jednym nieróżniczkowalnym członem jest $\\epsilon$, jednak zależy nam głównie na parametrach $\\mu$ oraz $\\sigma$. Możemy policzyć gradienty w następujący sposób (w rzeczywistości biblioteki do uczenia sieci neuronowych obliczają te pochodne za nas):\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\Delta_\\mu &= \\frac{\\partial f}{\\partial \\theta} + \\frac{\\partial f}{\\partial \\mu} \\\\\n",
    "    \\Delta_\\sigma &= \\frac{\\partial f}{\\partial \\theta} \\frac{\\epsilon}{\\sigma} + \\frac{\\partial f}{\\partial \\sigma}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Parametry są aktualizowane w następujący sposób:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mu^{(t+1)} &= \\mu^{t} - \\alpha \\Delta_\\mu \\\\\n",
    "    \\sigma^{(t+1)} &= \\sigma^t - \\alpha \\Delta_\\sigma\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Tak zdefiniowane uczenie jest nazywane _Bayes by Backprop_ i jest kluczowym elementem Bayesowskich Sieci Neuronowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior\n",
    "\n",
    "Poniższa implementacja bayesowskich sieci neuronowych jest oparta na pracy `https://arxiv.org/pdf/1505.05424.pdf`. Najpierw zaimplementujmy prior dla wag sieci. Wykorzystana będzie tutaj mikstura dwóch rozkładów normalnych. Implementacja ta jest zgodna z opisem w punkcie `3.3. Scale mixture prior` w przytoczonej publikacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoGaussianMixturePrior:\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        sigma_1: float = 1, \n",
    "        sigma_2: float = 1e-6, \n",
    "        mixing: float = 0.5,\n",
    "    ):\n",
    "        self.mixing = mixing\n",
    "        \n",
    "        self.w_prior_1 = torch.distributions.Normal(0, sigma_1)\n",
    "        self.w_prior_2 = torch.distributions.Normal(0, sigma_2)\n",
    "        \n",
    "        self.b_prior_1 = torch.distributions.Normal(0, sigma_1)\n",
    "        self.b_prior_2 = torch.distributions.Normal(0, sigma_2)\n",
    "        \n",
    "    def log_prob(self, weights: torch.Tensor, biases: torch.Tensor):\n",
    "        w_log_prior_1 = self.w_prior_1.log_prob(weights).exp()\n",
    "        w_log_prior_2 = self.w_prior_2.log_prob(weights).exp()\n",
    "        \n",
    "        w_prior = self.mixing * w_log_prior_1 + (1 - self.mixing) * w_log_prior_2\n",
    "        \n",
    "        b_log_prior_1 = self.b_prior_1.log_prob(biases).exp()\n",
    "        b_log_prior_2 = self.b_prior_2.log_prob(biases).exp()\n",
    "        \n",
    "        b_prior = self.mixing * b_log_prior_1 + (1 - self.mixing) * b_log_prior_2\n",
    "    \n",
    "        # We don't want this log probability to depend on \n",
    "        # the actual number of network parameters (weights+biases),\n",
    "        # so we compute the mean instead of a sum.\n",
    "        return w_prior.log().mean() + b_prior.log().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 1 (2 pkt) - Liniowa warstwa Bayesowska\n",
    "Uzupełnij poniższą implementację bayesowskiej warstwy liniowej. Pamiętaj, że w omówionym podejściu wykorzystujemy rozkład normalny, a każda waga sieci jest określona przez parametry: $\\mu$ oraz $\\sigma^2$. \n",
    "\n",
    "- w funkcji `__init__()` zadeklaruj i zainicjuj wyuczalne parametry rozkładów normalnych, osobno dla wag sieci (`weight`) oraz obciążeń (`biases`)\n",
    "- w funkcji `forward()` wylosuj wagi oraz obciążenia z przygotowanych rozkładów; użyj sztuczki z reparametryzacją; pamiętaj, że wariancja/odchylenie standardowe nie może być ujemne (zobacz rozdział: `3.2. Gaussian variational posterior` w podanej publikacji)\n",
    "- w funkcji `variational_log_prob()` oblicz logarytm prawdopodobieństwa wariacyjnego $\\log q_\\phi(\\theta^{(i)} | \\mathcal{D}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb57aef70c301503af56c86cfd6d08f3",
     "grade": true,
     "grade_id": "bayesian-linear",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class BayesianLinear(nn.Module):\n",
    "    \"\"\"Main reference: https://arxiv.org/pdf/1505.05424.pdf\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        num_input_features: int,\n",
    "        num_output_features: int,\n",
    "        prior: TwoGaussianMixturePrior,\n",
    "    ):\n",
    "        \"\"\"Implement initialization of weights and biases values\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.prior = prior\n",
    "        \n",
    "        self.last_weights_ = None\n",
    "        self.last_biases_ = None\n",
    "        \n",
    "        # Define weights parameters and initialize them using uniform distribution\n",
    "        # TU WPISZ KOD\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        # Define biases parameters and initialize them using uniform distribution\n",
    "        # TU WPISZ KOD\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Implement forward inference using reparametrization trick\"\"\"\n",
    "        weights = ...\n",
    "        biases = ...\n",
    "        \n",
    "        # TU WPISZ KOD\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        self.last_weights_ = weights\n",
    "        self.last_biases_ = biases\n",
    "        \n",
    "        return x @ weights + biases\n",
    "        \n",
    "    def prior_log_prob(self) -> torch.Tensor:\n",
    "        \"\"\"Calculates the prior log prob of sampled weights and biases.\"\"\"\n",
    "        return self.prior.log_prob(weights=self.last_weights_, biases=self.last_biases_)\n",
    "        \n",
    "    def variational_log_prob(self) -> torch.Tensor:\n",
    "        \"\"\"Implement the variational log prob.\"\"\"\n",
    "        # TU WPISZ KOD\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesowski Wielowarstwowy Perceptron\n",
    "Używając powyższej bayesowskiej wartstwy liniowej możemy zaimplementować bayesowską wersję wielowarstwowego perceptrona (ang. *MLP*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianMLP(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_input_features: int,\n",
    "        num_hidden_features: int,\n",
    "        num_output_classes: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_1 = BayesianLinear(\n",
    "            num_input_features, num_hidden_features, \n",
    "            prior=TwoGaussianMixturePrior(),\n",
    "        )\n",
    "        self.layer_2 = BayesianLinear(\n",
    "            num_hidden_features, num_output_classes, \n",
    "            prior=TwoGaussianMixturePrior(),\n",
    "        )\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.sigmoid(self.layer_1(x))\n",
    "        x = self.softmax(self.layer_2(x))\n",
    "        return x\n",
    "        \n",
    "    def prior_log_prob(self) -> torch.Tensor:\n",
    "        log_prob = 0\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, BayesianLinear):\n",
    "                log_prob += module.prior_log_prob()\n",
    "        return log_prob\n",
    "        \n",
    "    def variational_log_prob(self) -> torch.Tensor:\n",
    "        log_prob = 0\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, BayesianLinear):\n",
    "                log_prob += module.variational_log_prob()\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 2 (1.5 pkt) - ELBO dla `N` próbek Monte Carlo\n",
    "Zaimplementuj liczenie ELBO korzystając ze wzoru $(1)$. Zastosuj funkcję kosztu `Negative Log Likelihood (NLL)` i pamiętaj, że w ten sposób człon: $- \\log p(\\mathcal{D}|\\mathbf{w}^{(i)})$ będzie w pełni obliczany przez NLL (jego wartość należy dodać do łącznego kosztu, a nie odejmować!). Dodatkowo należy podkreślić, że log likelihood próbki danych to suma log likelihood'ów każdego z elementów zbioru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5481d2f417bf9928de5d6580f62aa0a8",
     "grade": true,
     "grade_id": "elbo",
     "locked": false,
     "points": 1.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Union, Tuple\n",
    "\n",
    "\n",
    "class ELBO(nn.Module):\n",
    "    def __init__(self, N: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.N = N\n",
    "        self.nll = nn.NLLLoss(reduction=\"none\")\n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        model: nn.Module, \n",
    "        inputs: torch.Tensor,\n",
    "        targets: torch.Tensor,\n",
    "        *,\n",
    "        return_predictions: bool = False,\n",
    "    ) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        \"\"\"Calculate loss according to the equation (2) of https://arxiv.org/abs/1505.05424\"\"\"\n",
    "        predictions = []\n",
    "        log_posteriors = []\n",
    "        log_priors = []\n",
    "        \n",
    "        for _ in range(self.N):\n",
    "            preds = model(inputs)\n",
    "            \n",
    "            # TU WPISZ KOD\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "        loss = ...\n",
    "\n",
    "        # TU WPISZ KOD\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        if return_predictions:\n",
    "            return loss, torch.stack(predictions, dim=-1)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ewaluacja modelu\n",
    "Wykorzystamy tutaj zbiór MNIST (ręcznie pisanych cyfr) i wykonamy kilka analiz, aby zobaczyć gdzie model był pewien swoich decyzji (zarówno tych poprawnych jak i błędnych) oraz zobaczymy przykłady, gdzie model nie był pewien predykcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = utils.load_mnist_datasets(limit_train_samples_to=1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianMLP(\n",
    "    num_input_features=28 * 28,  # pixels\n",
    "    num_hidden_features=128,  # arbitrary number\n",
    "    num_output_classes=10,  # num of digits\n",
    ")\n",
    "\n",
    "loss_fun = ELBO(N=10)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=1e-3, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics, test_metrics = utils.fit_elbo(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    valid_dataset=test_dataset,\n",
    "    loss_function=loss_fun,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.show_learning_curve(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.show_accuracy_curve(train_metrics, test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best training accuracy: {max(train_metrics['acc'])}\")\n",
    "print(f\"Best testing accuracy: {max(test_metrics['acc'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samplings = 10\n",
    "analyzer = utils.Analyzer(model, test_dataset, num_samplings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.visualize_samples(\n",
    "    *analyzer.get_top_k_high_confidence_correct(10)\n",
    ")\n",
    "print(\"Top high confidence correct predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.visualize_samples(\n",
    "    *analyzer.get_top_k_low_confidence_correct(10)\n",
    ")\n",
    "print(\"Top low confidence correct predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.visualize_samples(\n",
    "    *analyzer.get_top_k_low_confidence_mistakes(10)\n",
    ")\n",
    "\n",
    "print(\"Top low confidence wrong predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.visualize_samples(\n",
    "    *analyzer.get_top_k_high_confidence_mistakes(10)\n",
    ")\n",
    "\n",
    "print(\"Top high confidence wrong predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 3 (0.1 pkt)\n",
    "Przypisz do zmiennych `layer_1_means` oraz `layer_2_means` wartości parametrów średnich rozkładu normalnego $\\mu$ dla odpowiednio pierwszej i drugiej warstwy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e41d84ee9a2b0e6ecb6cb281de505a9",
     "grade": true,
     "grade_id": "layer1_mean",
     "locked": false,
     "points": 0.05,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "layer_1_means = ...\n",
    "# TU WPISZ KOD\n",
    "raise NotImplementedError()\n",
    "\n",
    "utils.visualize_weights(layer_1_means, \"layer input -> hidden\")\n",
    "print(\"Histogram of weights for layer 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb4227a079bace3f8c053eae72cb4ada",
     "grade": true,
     "grade_id": "layer2_mean",
     "locked": false,
     "points": 0.05,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "layer_2_means = ...\n",
    "# TU WPISZ KOD\n",
    "raise NotImplementedError()\n",
    "\n",
    "utils.visualize_weights(layer_2_means, \"layer hidden -> output\")\n",
    "print(\"Histogram of weights for layer 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc25162cf925e21d595ec6fce2615a28",
     "grade": false,
     "grade_id": "sensitivity-study",
     "locked": true,
     "points": 1.4,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "# Zadanie 4 (1.4 pkt)\n",
    "Zbadaj wpływ hiperparametrów na działanie modelu:\n",
    "- parametry w rozkładzie prior (tzn. `sigma_1`, `sigma_2`, `mixing`)\n",
    "- co się stanie jeśli zastosujemy tylko jeden rozkład normalny jako prior (zamiast mikstury)?\n",
    "- rozmiar mini-paczki (`batch_size`)\n",
    "- współczynnik uczenia (`learning_rate`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
